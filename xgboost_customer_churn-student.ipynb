{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction with XGBoost\n",
    "_**Using Gradient Boosted Trees to Predict Mobile Customer Departure**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host_The_Model)\n",
    "1. [Evaluate](#Evaluate)\n",
    "1. [(Must) Clean-up](#clean_up)\n",
    "1. [Predict in batch mode using Batch Transform](#batch_transform)\n",
    "1. [(Optional) Bonus 1 - Tune the model using different/additional hyperparameters](#bonus_1)\n",
    "1. [(Optional) Bonus 2 - Use SageMaker automatic model tuning](#bonus_2)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "_This notebook has been adapted from an [AWS blog post](https://aws.amazon.com/blogs/ai/predicting-customer-churn-with-amazon-machine-learning/)_\n",
    "\n",
    "Losing customers is costly for any business.  Identifying unhappy customers early on gives you a chance to offer them incentives to stay.  This notebook describes using machine learning (ML) for the automated identification of unhappy customers, also known as customer churn prediction. ML models rarely give perfect predictions though, so this notebook is also about how to incorporate the relative costs of prediction mistakes when determining the financial outcome of using ML.\n",
    "\n",
    "We use an example of churn that is familiar to all of us–leaving a mobile phone operator.  Seems like I can always find fault with my provider du jour! And if my provider knows that I’m thinking of leaving, it can offer timely incentives–I can always use a phone upgrade or perhaps have a new feature activated–and I might just stick around. Incentives are often much more cost effective than losing and reacquiring a customer.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "Specify your name (will be displayed in the class live leaderboard, So nothing too funny plz :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below cell to Specify:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting. In this case we'll use Sagemaker's default bucket.\n",
    "- The IAM role arn used to give training and hosting access to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-xgboost-churn'\n",
    "print(f'Using bucket: {bucket}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import the Python libraries we'll need for the remainder of the exercise.\n",
    "In particular note:\n",
    "1. [Pandas](https://pandas.pydata.org/) - A Python library for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series.\n",
    "2. [Numpy](http://www.numpy.org/) - A Python library that adds support for large, multi-dimensional arrays and matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data\n",
    "\n",
    "Mobile operators have historical records on which customers ultimately ended up churning and which continued using the service. We can use this historical information to construct an ML model of one mobile operator’s churn using a process called training. After training the model, we can pass the profile information of an arbitrary customer (the same profile information that we used to train the model) to the model, and have the model predict whether this customer is going to churn. Of course, we expect the model to make mistakes–after all, predicting the future is tricky business! But I’ll also show how to deal with prediction errors.\n",
    "\n",
    "The dataset we use is publicly available and was mentioned in the book [Discovering Knowledge in Data](https://www.amazon.com/dp/0470908742/) by Daniel T. Larose. It is attributed by the author to the University of California Irvine Repository of Machine Learning Datasets.  Let's download and read that dataset in now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://floor28/churn.zip ./\n",
    "!unzip -o churn.zip\n",
    "!ls -l 'Data sets/churn.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Load into a Pandas Dataframe:  \n",
    "churn.txt is a CSV file, load it into a Pandas Dataframe by using the relevant [Pandas method for reading input](https://pandas.pydata.org/pandas-docs/stable/api.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = pd.REPLACE_ME('./Data sets/churn.txt') # Use pandas to read in CSV format\n",
    "pd.set_option('display.max_columns', 500)\n",
    "churn.head(5) # Print first five records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By modern standards, it’s a relatively small dataset, with only 3,333 records, where each record uses 21 attributes to describe the profile of a customer of an unknown US mobile operator. The attributes are:\n",
    "\n",
    "- `State`: the US state in which the customer resides, indicated by a two-letter abbreviation; for example, OH or NJ\n",
    "- `Account Length`: the number of days that this account has been active\n",
    "- `Area Code`: the three-digit area code of the corresponding customer’s phone number\n",
    "- `Phone`: the remaining seven-digit phone number\n",
    "- `Int’l Plan`: whether the customer has an international calling plan: yes/no\n",
    "- `VMail Plan`: whether the customer has a voice mail feature: yes/no\n",
    "- `VMail Message`: presumably the average number of voice mail messages per month\n",
    "- `Day Mins`: the total number of calling minutes used during the day\n",
    "- `Day Calls`: the total number of calls placed during the day\n",
    "- `Day Charge`: the billed cost of daytime calls\n",
    "- `Eve Mins, Eve Calls, Eve Charge`: the billed cost for calls placed during the evening\n",
    "- `Night Mins`, `Night Calls`, `Night Charge`: the billed cost for calls placed during nighttime\n",
    "- `Intl Mins`, `Intl Calls`, `Intl Charge`: the billed cost for international calls\n",
    "- `CustServ Calls`: the number of calls placed to Customer Service\n",
    "- `Churn?`: whether the customer left the service: true/false\n",
    "\n",
    "The last attribute, `Churn?`, is known as the target attribute–the attribute that we want the ML model to predict.  Because the target attribute is binary, our model will be performing binary prediction, also known as binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "As Data scientists, before plugging our data into an ML algorithm, we must first explore our data to understand:\n",
    "1. Which features are categorical and which are numeric. Which features categorical Numpy wrongly classified as numeric.\n",
    "2. Each feature values distribution and cardinality.\n",
    "3. Which features we should drop from the dataset because we can easily see they would not contribute to the model, or because they are highly correlated with other features.\n",
    "\n",
    "You should really explore all features, but in this notebook, we decided to focus on specific features we know are interesting.  \n",
    "Let's start exploring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.State.value_counts(sort=True).plot.pie()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note `State` appears to be quite evenly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosstab(column):\n",
    "    display(pd.crosstab(index=churn[column], columns='% observations', normalize='columns'))\n",
    "crosstab('Phone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Phone` takes on too many unique values to be of any practical use. It's possible parsing out the prefix could have some value, but without more context on how these are allocated, we should avoid using it.  \n",
    "Let's drop the `Phone` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = churn.drop('Phone', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn['Churn?'].value_counts(sort=True).plot.pie(autopct='%1.f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see only 14% of customers churned, so there is some class imabalance, but nothing extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Day Mins',y='Churn?',data=churn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the total number of calling minutes used during the day is bigger in churned customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.groupby('Churn?').mean()['Day Mins']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that though there are only 14% customers churned, the mean of the total number of calling minutes used during the day is bigger in churned customers. This support the boxplot we saw in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x='CustServ Calls',data=churn, hue='Churn?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the number of calls placed to Customer Service is much lower in churnded customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for each numeric features\n",
    "#display(churn.describe())\n",
    "%matplotlib inline\n",
    "hist = churn.hist(bins=30, sharey=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the numeric features are surprisingly nicely distributed, with many showing bell-like gaussianity.  `VMail Message` being a notable exception (and `Area Code` showing up as a feature we should convert to non-numeric).  \n",
    "Let's convert `Area Code` to non-numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn['Area Code'] = churn['Area Code'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's look at the relationship between each of the features and our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in churn.select_dtypes(include=['object']).columns:\n",
    "    if column != 'Churn?':\n",
    "        display(pd.crosstab(index=churn[column], columns=churn['Churn?'], normalize='index'))\n",
    "\n",
    "for column in churn.select_dtypes(exclude=['object']).columns:\n",
    "    print(column)\n",
    "    hist = churn[[column, 'Churn?']].hist(by='Churn?', bins=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly we see that churners appear:\n",
    "- Fairly evenly distributed geographically\n",
    "- More likely to have an international plan\n",
    "- Less likely to have a voicemail plan\n",
    "- To exhibit some bimodality in daily minutes (either higher or lower than the average for non-churners)\n",
    "- To have a larger number of customer service calls (which makes sense as we'd expect customers who experience lots of problems may be more likely to churn)\n",
    "\n",
    "In addition, we see that churners take on very similar distributions for features like `Day Mins` and `Day Charge`.  That's not surprising as we'd expect minutes spent talking to correlate with charges.  Let's dig deeper into the relationships between our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the correlation between each possible features pair as a scatter plot\n",
    "pd.plotting.scatter_matrix(churn, figsize=(16, 16))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see several features that essentially have 100% correlation with one another.  Including these feature pairs in some machine learning algorithms can create catastrophic problems, while in others it will only introduce minor redundancy and bias.  Let's remove one feature from each of the highly correlated pairs: Day Charge from the pair with Day Mins, Night Charge from the pair with Night Mins, Intl Charge from the pair with Intl Mins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = churn.drop(['Day Charge', 'Eve Charge', 'Night Charge', 'Intl Charge'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've cleaned up our dataset, let's determine which algorithm to use.  As mentioned above, there appear to be some variables where both high and low (but not intermediate) values are predictive of churn.  In order to accommodate this in an algorithm like linear regression, we'd need to generate polynomial (or bucketed) terms.  Instead, let's attempt to model this problem using gradient boosted trees.  Amazon SageMaker provides an XGBoost container that we can use to train in a managed, distributed setting, and then host as a real-time prediction endpoint.  XGBoost uses gradient boosted trees which naturally account for non-linear relationships between features and the target variable, as well as accommodating complex interactions between features.\n",
    "\n",
    "Amazon SageMaker XGBoost can train on data in either a CSV or LibSVM format.  For this example, we'll stick with CSV.  It should:\n",
    "- Have the predictor variable in the first column\n",
    "- Not have a header row\n",
    "\n",
    "But first, let's convert our categorical features into numeric features, as the algorithm expects numerical values only.\n",
    "This means adding each possible catagorical value as a new colume.\n",
    "Replace `REPLACE_ME` with the pandas method that Converts categorical variable into dummy/indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.REPLACE_ME(churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a new dataframe with the 'Churn?_True.' colume being the first column, the trailed by \n",
    "# all other columes except 'Churn?_False.' and 'Churn?_True.'.\n",
    "model_data = pd.concat([model_data['Churn?_True.'], \n",
    "                        model_data.drop(['Churn?_False.', 'Churn?_True.'], axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.head(5) # notice we now have many more columes generated to reperesent all categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's split the data into training, validation, and test sets.  This will help prevent us from overfitting the model, and allow us to test the models accuracy on data it hasn't already seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = np.split(\n",
    "    model_data.sample(frac=1, random_state=1729), \n",
    "    [int(0.7 * len(model_data)), \n",
    "     int(0.9 * len(model_data))])\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload these files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train\n",
    "Amazon SageMaker provides several [built-in machine learning algorithms](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html) that you can use for a variety of problem types. Amazon SageMaker algorithms are packaged as Docker images. This gives you the flexibility to use almost any algorithm code with Amazon SageMaker, regardless of implementation language, dependent libraries, frameworks, and so on.\n",
    "Each built-in algorithm packed in its own Docker image found in the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html). We'll specify the relevant container image for each training job.  \n",
    "\n",
    "Moving onto training, first we'll need to specify the image for the XGBoost algorithm container.\n",
    "\n",
    "In the next cell replace **algorithm_name** with the relevant algorithm name from the \"Training Image and Inference Image Registry Path\" colume in this [table](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html). Enter the algoritm name in lower case and without the trailing colon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'replace_me_with_algorithm_name')\n",
    "display(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SageMaker Python SDK](https://sagemaker.readthedocs.io/en/latest/)  is an open source library for training and deploying machine-learned models on Amazon SageMaker. \n",
    "The SDK provides several high-level abstractions for working with Amazon SageMaker. These are:\n",
    "\n",
    "* [Estimators](https://sagemaker.readthedocs.io/en/latest/estimators.html): Encapsulate training on SageMaker.\n",
    "* [Models](https://sagemaker.readthedocs.io/en/latest/model.html): Encapsulate a trained ML model. Can be deployed to an endpoint.\n",
    "* [Predictors](https://sagemaker.readthedocs.io/en/latest/predictors.html): Provide real-time inference and transformation using Python data-types against a SageMaker endpoint.\n",
    "* [Session](https://sagemaker.readthedocs.io/en/latest/session.html): Provides a collection of methods for working with SageMaker resources.\n",
    "\n",
    "We'll start by creating the [xgboost Estimator](https://sagemaker.readthedocs.io/en/latest/estimators.html). The mandatory paramters are: image_name (str), role (str), sagemaker_session (session), train_instance_type (str), and train_instance_count (int).\n",
    "\n",
    "For this training job, provide these parameters: **image_name = container, role=role, train_instance_count = 1, train_instance_type = 'ml.m4.xlarge', sagemaker_session = session**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the SageMaker Estimator object\n",
    "xgb = sagemaker.estimator.Estimator(image_name = ...,\n",
    "                                    role = ..., \n",
    "                                    train_instance_count = ..., \n",
    "                                    train_instance_type = ...,\n",
    "                                    output_path = 's3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session = ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ML algorithm is configured and tuned with specific hyperparameters, the hyperparameters changes the way the algorithm works ([what is a hyperpramaeter?](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning%29)).\n",
    "\n",
    "The XGBoost hyperparamaters are described in the [XGBoost documentation](https://xgboost.readthedocs.io/en/latest/parameter.html).\n",
    "\n",
    "For this example, the required hyperparameters for the XGBoost algorithm are:\n",
    "\n",
    "* `objective` - Specifies the learning task and the corresponding learning objective. please use **binary:logistic** for binary classification task.  \n",
    "* `num_round` - Controls the number of boosting rounds. This is essentially the subsequent models that are trained using the residuals of previous iterations. More rounds should produce a better fit on the training data, but can be computationally expensive or lead to overfitting.\n",
    "\n",
    "A few other key hyperparameters are:\n",
    "* `max_depth` - Controls how deep each tree within the algorithm can be built. Deeper trees can lead to better fit, but are more computationally expensive and can lead to overfitting. There is typically some trade-off in model performance that needs to be explored between a large number of shallow trees and a smaller number of deeper trees.\n",
    "* `subsample` controls - Sampling of the training data. This technique can help reduce overfitting, but setting it too low can also starve the model of data.\n",
    "* `eta` - Controls how aggressive each round of boosting is. Larger values lead to more conservative boosting.\n",
    "* `gamma` - Controls how aggressively trees are grown. Larger values lead to more conservative models.\n",
    "\n",
    "Use the [xgb.set_hyperparameters](https://sagemaker.readthedocs.io/en/latest/estimators.html) to set the hyperparameters value you choose after reading the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyperparameters\n",
    "xgb.set_hyperparameters(objective=...,\n",
    "                        num_round=...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're training with CSV file format, we'll create [`s3_input`](https://sagemaker.readthedocs.io/en/latest/session.html?highlight=sagemaker.session.s3_input) objects that our training function can use as a pointer to the files type and location in S3.\n",
    "\n",
    "Run the following for the training data input and the validation data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the data inputs\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/validation'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we are ready to train.\n",
    "To train use the [xgb.fit()](https://sagemaker.readthedocs.io/en/latest/estimators.html) function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've completed training - pay attention to the final validation-error. A lower value is better.  \n",
    "Let's post this value to the classroom leaderboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = xgb.training_job_analytics.dataframe()\n",
    "validation_error = df[df.metric_name.isin(['validation:error'])].at[0, \"value\"]\n",
    "\n",
    "display('validation_error='+str(validation_error))\n",
    "\n",
    "#import importlib, classroom\n",
    "#importlib.reload(classroom)\n",
    "#init_classroom(my_name, call_home=True)\n",
    "#from classroom import report_algo_objective\n",
    "\n",
    "#report_algo_objective(validation_error, xgb.hyperparam_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='Host_The_Model'></a>\n",
    "## Host The Model\n",
    "\n",
    "Now that we've trained the algorithm, let's create a model and deploy it to a hosted endpoint.\n",
    "\n",
    "We'll do this using [estimator](https://sagemaker.readthedocs.io/en/latest/estimators.html) `deploy()` method.\n",
    "\n",
    "Provide these parameters: **initial_instance_count = 1** and **instance_type = 'ml.m4.xlarge'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model\n",
    "xgb_predictor = xgb.deploy(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Evaluate\n",
    "\n",
    "Now that we have a hosted endpoint running, we can make real-time predictions from our model very easily, simply by making an http POST request.  But first, we'll need to setup serializers and deserializers for passing our `test_data` NumPy arrays to the model behind the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "xgb_predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use a simple function to:\n",
    "1. Loop over our test dataset\n",
    "1. Split it into mini-batches of rows \n",
    "1. Convert those mini-batchs to CSV string payloads\n",
    "1. Retrieve mini-batch predictions by invoking the XGBoost endpoint\n",
    "1. Collect predictions and convert from the CSV output, our model provides, into a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "predictions = predict(test_data.to_numpy()[:,1:])\n",
    "\n",
    "assert(len(predictions)==334) # Just checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to compare the performance of a machine learning model, but let's start by simply by comparing actual to predicted values.  In this case, we're simply predicting whether the customer churned (`1`) or not (`0`), which produces a simple [confusion matrix](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(index=test_data.iloc[:, 0], columns=np.round(predictions), rownames=['actual'], colnames=['predictions'], margins='true')\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note, due to randomized elements of the algorithm, your results may differ slightly._\n",
    "\n",
    "Of the 48 churners, we've correctly predicted ~39 of them (_True Positives (TP)_). And, we incorrectly predicted 4 customers would churn who then ended up not doing so (_False Positives (FP)_).  There are also ~9 customers who ended up churning, that we predicted would not (_False Negatives (FN)_).\n",
    "\n",
    "Now let's calculate the accuracy, precision and recall (these are common mesurments that assists in evaluating the quality of our model and also compare between differnt models):\n",
    "\n",
    "_Accuracy_: Overall, how often is the classifier correct? (TP+TN)/total\n",
    "\n",
    "_Precision_: When it predicts yes, how often is it correct? TP/(predicted yes)\n",
    "\n",
    "_Recall_: When it's actually yes, how often does it predict yes? TP/(actual yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = confusion_matrix['All']['All']\n",
    "TP = [please complete...]\n",
    "TN = [please complete...]\n",
    "accuracy = ([please complete...]\n",
    "precision = [please complete...]\n",
    "recall = [please complete...]\n",
    "print ('Accuracy: {}'.format(accuracy))\n",
    "print ('Precision: {}'.format(precision))\n",
    "print ('Recall: {}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important point here is that because of the `np.round()` function above we are using a simple threshold (or cutoff) of 0.5.  Our predictions from `xgboost` come out as continuous values between 0 and 1 and we force them into the binary classes that we began with.  However, because a customer that churns is expected to cost the company more than proactively trying to retain a customer who we think might churn, we should consider adjusting this cutoff.  That will almost certainly increase the number of false positives, but it can also be expected to increase the number of true positives and reduce the number of false negatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='clean_up'></a>\n",
    "### (Must) Clean-up\n",
    "\n",
    "If you're ready to be done with this notebook, please run the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='batch_transform'></a>\n",
    "### Predict in batch mode using Batch Transform\n",
    "What if you want to get inference (predict) over very large quantities of data? For example your input data is in S3, and you would like the inference results to be stored in S3 as well.\n",
    "What if you need to split the work over several instances to reduce job duration?  \n",
    "With some hard work you could do it by coding a custom workflow like this one:\n",
    "1. Start N required hosted real-time endpoints (instances)\n",
    "2. Starts a driver program (that we need to code) to read records from S3 (add support for several popular input formats of course)\n",
    "3. Sends a single/batch of records to each fo the hosted endpoints, possibly in parallel - so use async IO or multi-threaded approach\n",
    "4. Retries if something fails. Expose parameters to control driver behavior. Log the driver activity. Establish error handling. Report progress.\n",
    "5. Collect results to a driver temp storage and store final results in S3\n",
    "6. Shutdown endpoints to save $\n",
    "\n",
    "As it happens this is exactly what [SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html) provides.  \n",
    "  \n",
    "Let's demo how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blow up our full dataset by 1000x to make things more interesting from scale perspective\n",
    "model_data.drop(['Churn?_True.'], axis=1).to_csv('features_without_label.csv', header=False, index=False)\n",
    "\n",
    "import os\n",
    "total_size_mb = int(os.path.getsize('features_without_label.csv')*1000/1024/1024.0)\n",
    "print('Upload '+str(total_size_mb)+'MB of input data to S3 (as 1000 CSV files).')\n",
    "\n",
    "for i in range(1000):\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(\n",
    "        os.path.join(prefix, 'batch-input/features_without_label_'+str(i)+'.csv')).upload_file('features_without_label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the input data in place, let's create and start a batch transform job (should take about 5min to complete using two instances):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input = 's3://{}/{}/batch-input'.format(bucket, prefix) # The location of the dataset to transform\n",
    "batch_output = 's3://{}/{}/batch-output'.format(bucket, prefix) # The location to store the results of the batch transform job\n",
    "\n",
    "# Define the job\n",
    "# Doc: https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.EstimatorBase.transformer\n",
    "transformer = xgb.transformer(\n",
    "    instance_count=2,\n",
    "    instance_type='ml.m5.large', \n",
    "    strategy='MultiRecord', # Send a bulk of records in each inference request\n",
    "    max_concurrent_transforms=2, # m5.large has two cores. Keep both of them busy\n",
    "    output_path=batch_output)\n",
    "\n",
    "# Start the job\n",
    "# Doc: https://sagemaker.readthedocs.io/en/stable/transformer.html#sagemaker.transformer.Transformer.transform\n",
    "transformer.transform(\n",
    "    data=batch_input, \n",
    "    data_type='S3Prefix', \n",
    "    content_type='text/csv', \n",
    "    split_type='Line')\n",
    "\n",
    "# Job is running in the background. You can view its metrics and logs in the console: https://console.aws.amazon.com/sagemaker/home?#/transform-jobs\n",
    "# Let's wait for it to finish\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job completed, let's take a look at the job output data output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = 's3://{}/{}/batch-output'.format(bucket, prefix)\n",
    "batch_output\n",
    "display(\"Here's our 1000 output files, one per input file:\")\n",
    "!aws s3 ls {batch_output}/ | wc -l \n",
    "display('\\nfirst 10 predictions from the last file:')\n",
    "!aws s3 cp {batch_output}/features_without_label_999.csv.out - | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "congrats! you were able to transform/infer 1000 CSV quickly by splitting the work on N machines. The only code you wrote is triggering the Batch Transform API. \n",
    "Batch transform can be part of your ML pipeline, or run on-demand. It can help with feature engineering, or with actual inference.   \n",
    "Learn more [here](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='bonus_1'></a>\n",
    "### (Optional) Bonus 1 - Tune the model using different/additional hyperparameters\n",
    "Use the [Estimator.set_hyperparameters](https://sagemaker.readthedocs.io/en/latest/estimators.html) and explore other hyperparameters, check out the [recommanded values](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html) for each hyper parameter.\n",
    "\n",
    "Try to get a lower validation-error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bonus 1 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='bonus_2'></a>\n",
    "### (Optional) Bonus 2 - Use SageMaker automatic model tuning\n",
    "See the [blog post on Automatic model tuning](https://aws.amazon.com/blogs/aws/sagemaker-automatic-model-tuning/)\n",
    "Call auto model tuning to achieve the lowest validation-error. \n",
    "Sit back, relax and appreciate how auto model tuning is far easier than manual tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bonus 2 code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
